<!DOCTYPE html>
<!--
	Landed by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
    <title>CV4DA - References</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css"
    /></noscript>
</head>

<body class="is-preload">
    <div id="page-wrapper">
        <!-- Header -->
        <header id="header">
            <h1 id="logo">
                <a href="index.html">Computer Vision for Driver Assistance</a>
            </h1>
            <nav id="nav">
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li>
                        <a href="technicals.html">Technicals</a>
                        <ul>
                            <li><a href="technicals.html">Introduction</a></li>
                            <li>
                                <a href="related-work.html">Related Work</a>
                                <ul>
                                    <li>
                                        <a href="traffic-sign-recognition.html">Traffic Sign Recognition</a
                      >
                    </li>
                    <li>
                      <a href="pedestrian-detection.html"
                        >Pedestrian Detection</a
                      >
                    </li>
                    <li>
                      <a href="vehicle-detection.html">Vehicle Detection</a>
                                    </li>
                                    <li>
                                        <a href="image-captioning.html">Image Captioning</a>
                                    </li>
                                </ul>
                            </li>
                            <li><a href="architecture.html">Architecture</a></li>
                            <!-- <li><a href="Dataset.html">Dataset</a></li> -->
                            <li><a href="sensors.html">Sensors</a></li>
                            <li>
                                <a href="successes-and-challenges.html">Successes and Challenges</a
                  >
                  <ul>
                    <li>
                      <a href="">Successes</a>
                            </li>
                            <li>
                                <a href="">Challenges</a>
                            </li>
                        </ul>
                    </li>

                    <li><a href="future-work.html">Future Work</a></li>
                </ul>
                </li>
                <li>
                    <a href="#">Resources</a>
                    <ul>
                        <!-- Project Resources-->
                        <li>
                            <a href="docs/project_1_proposal.pdf">Project Proposal</a>
                        </li>

                        <li>
                            <a href="#">Project Presentation</a>
                        </li>

                        <li><a href="references.html">References</a></li>
                        <li><a href="quiz.html">Quiz</a></li>

                        <!-- Learning Resources-->

                        <li>
                            <!-- Add Interactables like Convolution Visualizer
-->
                            <a href="#">Interactable Learning</a>
                            <ul>
                                <li><a href="quiz.html">Quiz</a></li>
                                <!-- TODO: Add Interactables like Convolution Visualizer
 | Fork, edit and integrate https://github.com/ezyang/convolution-visualizer -->
                                <li><a href="#">Convolution Visualizer
</a></li>
                                <li><a href="#">Technical Terms</a></li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <!-- <li><a href="elements.html">Elements</a></li> -->
                <!-- <li><a href="#" class="button primary">Sign Up</a></li> -->
                </ul>
            </nav>
        </header>

        <!-- Main -->
        <div id="main" class="wrapper style1">
            <div class="container">
                <header class="major">
                    <h2>References</h2>
                </header>

                <!-- Content -->
                <section id="content">
                    <!-- <a href="#" class="image fit"><img src="images/pic07.jpg" alt="" /></a> -->
                    <ul id="1">
                        [ 1 ] B. A. Plummer, L. Wang, C. M. Cervantes, J. C. Caicedo, J. Hockenmaier and S. Lazebnik, "Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models," 2015 IEEE International Conference on Computer Vision
                        (ICCV), 2015, pp. 2641-2649, doi: 10.1109/ICCV.2015.303.
                        <a href="https://ieeexplore.ieee.org/abstract/document/7410660">https://ieeexplore.ieee.org/abstract/document/7410660</a
              >
            </ul>
            <ul id="2">
              [ 2 ] Chapel, Marie-Neige, and Thierry Bouwmans. "Moving Objects
              Detection with a Moving Camera: A Comprehensive Review."
              ArXiv.org. January 15, 2020. Accessed September 23, 2021.
              <a href="https://arxiv.org/abs/2001.05238"
                >https://arxiv.org/abs/2001.05238.</a
              >
            </ul>

            <ul id="3">
              [ 3 ] Divvala, Santosh K., Alexei A. Efros, and Martial Hebert.
              "How Important Are Deformable Parts in the Deformable Parts
              Model?" ArXiv.org. June 16, 2012. Accessed September 23, 2021.
              <a href="https://arxiv.org/abs/1206.3714"
                >https://arxiv.org/abs/1206.3714.</a
              >
            </ul>

            <ul id="4">
              [4] Girshick, Ross B., Jeff Donahue, Trevor Darrell and J. Malik.
              "Rich Feature Hierarchies for Accurate Object Detection and
              Semantic Segmentation." 2014 IEEE Conference on Computer Vision
              and Pattern Recognition (2014): 580-587.
              <a href="https://arxiv.org/abs/1311.2524">
                https://arxiv.org/abs/1311.2524
              </a>
                    </ul>

                    <ul id="5">
                        [ 5 ] Mohammed, A.S.; Amamou, A.; Ayevide, F.K.; Kelouwani, S.; Agbossou, K.; Zioui, N. The Perception System of Intelligent Ground Vehicles in All Weather Conditions: A Systematic Literature Review. Sensors 2020, 20, 6532.
                        <a href="https://doi.org/10.3390/s20226532">https://doi.org/10.3390/s20226532</a
              >
            </ul>

            <ul id="6">
              [ 6 ] N. Dalal and B. Triggs, "Hitograms of oriented gradients for
              human detection," in Proc. IEEE Conf. Comput. Vis. Pattern
              Recogn., 2005, pp. 886–893.
              <a href="https://ieeexplore.ieee.org/document/1467360"
                >https://ieeexplore.ieee.org/document/1467360</a
              >
            </ul>

            <ul id="7">
              [ 7 ] Papineni, Kishore, S. Roukos, T. Ward and Wei-Jing Zhu.
              "Bleu: a Method for Automatic Evaluation of Machine Translation."
              ACL (2002).
              <a href="https://dl.acm.org/doi/10.3115/1073083.1073135"
                >https://dl.acm.org/doi/10.3115/1073083.1073135</a
              >
            </ul>
            <ul id="8">
              [ 8 ] P. Dhar, M. Z. Abedin, T. Biswas and A. Datta, "Traffic sign
              detection — A new approach and recognition using convolution
              neural network," 2017 IEEE Region 10 Humanitarian Technology
              Conference (R10-HTC), 2017, pp. 416-419, doi:
              10.1109/R10-HTC.2017.8288988.
              <a href="https://ieeexplore.ieee.org/abstract/document/8288988">
                https://ieeexplore.ieee.org/abstract/document/8288988</a
              >
            </ul>

            <ul id="9">
              [ 9 ] Redmon, Joseph & Divvala, Santosh & Girshick, Ross &
              Farhadi, Ali. (2016). You Only Look Once: Unified, Real-Time
              Object Detection. 779-788. 10.1109/CVPR.2016.91.
              <a href="https://arxiv.org/abs/1506.02640"
                >https://arxiv.org/abs/1506.02640</a
              >
            </ul>

            <ul id="10">
              [ 10 ] Ren, Shaoqing, Kaiming He, Ross B. Girshick and J. Sun.
              "Faster R-CNN: Towards Real-Time Object Detection with Region
              Proposal Networks." IEEE Transactions on Pattern Analysis and
              Machine Intelligence 39 (2015): 1137-1149.
              <a href="https://arxiv.org/abs/1506.01497"
                >https://arxiv.org/abs/1506.01497</a
              >
            </ul>

            <ul id="11">
              [ 11 ] R. Girshick, J. Donahue, T. Darrell and J. Malik,
              "Region-Based Convolutional Networks for Accurate Object Detection
              and Segmentation," in IEEE Transactions on Pattern Analysis and
              Machine Intelligence, vol. 38, no. 1, pp. 142-158, 1 Jan. 2016,
              doi: 10.1109/TPAMI.2015.2437384.
              <a href="https://ieeexplore.ieee.org/document/7112511"
                >https://ieeexplore.ieee.org/document/7112511</a
              >
            </ul>

            <ul id="12">
              [ 12 ] Russakovsky, O., Deng, J., Su, H. et al. ImageNet Large
              Scale Visual Recognition Challenge. Int J Comput Vis 115, 211–252
              (2015).
              <a href="https://doi.org/10.1007/s11263-015-0816-y"
                >https://doi.org/10.1007/s11263-015-0816-y</a
              >
            </ul>

            <ul id="13">
              [ 13 ] Simonyan, Karen, and Andrew Zisserman. "Very Deep
              Convolutional Networks for Large-Scale Image Recognition."
              ArXiv.org. April 10, 2015. Accessed September 23, 2021.
              <a href="https://arxiv.org/abs/1409.1556"
                >https://arxiv.org/abs/1409.1556.</a
              >
            </ul>

            <ul id="14">
              [ 14 ] Siogkas, George & Skodras, Evangelos. (2012). Traffic
              Lights Detection in Adverse Conditions Using Color, Symmetry and
              Spatiotemporal Information. VISAPP 2012 - Proceedings of the
              International Conference on Computer Vision Theory and
              Applications. 1.
              <a
                href="https://www.researchgate.net/publication/230601628_Traffic_Lights_Detection_in_Adverse_Conditions_Using_Color_Symmetry_and_Spatiotemporal_Information"
                >https://www.researchgate.net/publication/230601628_Traffic_Lights_Detection_in_Adverse_Conditions_Using_Color_Symmetry_and_Spatiotemporal_Information</a
              >
            </ul>

            <ul id="15">
              [ 15 ] Staudemeyer, Ralf & Morris, Eric. (2019). Understanding
              LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural
              Networks.
              <a href="https://arxiv.org/abs/1909.09586"
                >https://arxiv.org/abs/1909.09586</a
              >
            </ul>

            <ul id="16">
              [ 16 ] Vinyals, Oriol & Toshev, Alexander & Bengio, Samy & Erhan,
              Dumitru. (2016). Show and Tell: Lessons learned from the 2015
              MSCOCO Image Captioning Challenge. IEEE Transactions on Pattern
              Analysis and Machine Intelligence. 39. 1-1.
              10.1109/TPAMI.2016.2587640.
              <a href="https://arxiv.org/abs/1609.06647">
                https://arxiv.org/abs/1609.06647
              </a>
                    </ul>

                    <ul id="17">
                        [ 17 ] W. Li, Z. Qu, H. Song, P. Wang and B. Xue, "The Traffic Scene Understanding and Prediction Based on Image Captioning," in IEEE Access, vol. 9, pp. 1420-1427, 2021, doi: 10.1109/ACCESS.2020.3047091.
                        <a href="https://ieeexplore.ieee.org/document/9306804">https://ieeexplore.ieee.org/document/9306804</a
              >
            </ul>

            <ul id="18">
              [ 18 ] Xu, Ke, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C.
              Courville, R. Salakhutdinov, R. Zemel and Yoshua Bengio. "Show,
              Attend and Tell: Neural Image Caption Generation with Visual
              Attention." ICML (2015).
              <a href="https://arxiv.org/abs/1502.03044"
                >https://arxiv.org/abs/1502.03044</a
              >
            </ul>
          </section>
        </div>
      </div>

      <!-- Footer -->
      <footer id="footer">
        <ul class="icons">
          <!-- <li>
                    <a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a
            >
          </li> -->
          <!-- <li>
            <a href="#" class="icon brands alt fa-facebook-f"
              ><span class="label">Facebook</span></a
            >
          </li> -->
          <li>
            <a
              href="https://www.linkedin.com/in/henry-lao/"
              class="icon brands alt fa-linkedin-in"
              ><span class="label">LinkedIn</span></a
            >
          </li>
          <!-- <li>
            <a href="#" class="icon brands alt fa-instagram"
              ><span class="label">Instagram</span></a
            >
          </li> -->
          <li>
            <a
              href="https://github.com/henrylao"
              class="icon brands alt fa-github"
              ><span class="label">GitHub</span></a
            >
          </li>
          <li>
            <a
              href="mailto: hlao1995@gmail.com"
              class="icon solid alt fa-envelope"
              ><span class="label">Email</span></a
            >
          </li>
        </ul>
        <ul class="copyright">
          <li>&copy; CV4DA. All rights reserved.</li>
          <li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                    </ul>
                    </footer>
            </div>

            <!-- Scripts -->
            <script src="assets/js/jquery.min.js"></script>
            <script src="assets/js/jquery.scrolly.min.js"></script>
            <script src="assets/js/jquery.dropotron.min.js"></script>
            <script src="assets/js/jquery.scrollex.min.js"></script>
            <script src="assets/js/browser.min.js"></script>
            <script src="assets/js/breakpoints.min.js"></script>
            <script src="assets/js/util.js"></script>
            <script src="assets/js/main.js"></script>
</body>

</html>
<li>&copy; CV4DA. All rights reserved.</li>
<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
</ul>
</footer>
</div>

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/jquery.dropotron.min.js"></script>
<script src="assets/js/jquery.scrollex.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>
</body>

</html>